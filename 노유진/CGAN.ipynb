{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795f3fe3",
   "metadata": {},
   "source": [
    "Discriminator와 Generator가 모두 어떤 추가적인 정보 y에 의해 conditioning 된다면 GAN은 조건부 모델로 확장 가능하다는 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b392d0a",
   "metadata": {},
   "source": [
    "$min\\,max\\,V(D,G) = E_{x~p_{data(x)}}[logD(x|y)]+E_{z~p_{z(z)}}[log(1-D(G(z|y)))]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7d387",
   "metadata": {},
   "source": [
    "**Generator**\\\n",
    "차원(size)이 100인 prior noise z\\\n",
    "z와 y가 각각 size 200, 1000인 hidden layer(ReLu)로 mapping\\\n",
    "z와 y는 size 1200인 hidden layer로 합쳐짐(ReLu)\\\n",
    "마지막으로 784차원 MNIST 샘플을 생성하기 위한 출력으로 최종 sigmoid 단위 레이어가 존재 (784차원으로 변환됨, MNIST 이미지는 28^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90414ce7",
   "metadata": {},
   "source": [
    "**Discriminator**\\\n",
    "x를 240 unit와 5 piece로 구성된 maxout layer에 mapping\\\n",
    "y를 50 unit와 5 piece으로 구성된 maxout layer에 mapping\\\n",
    "240 unit, 4 piece의 maxout layer로 합쳐진 후 Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8279007",
   "metadata": {},
   "source": [
    "모델\\\n",
    "크기가 100이고, 초기 학습률이 0.1\\\n",
    "모멘텀은 0.5 ~ 0.7 사용\\\n",
    "Dropout은 G와 D에 0.5로 적용\\\n",
    "검증 세트에 대한 로그 가능성의 최선 추정치를 중지점으로 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b374db9",
   "metadata": {},
   "source": [
    "가장 잘 작동하는 모델의 G\\\n",
    "크기 100의 가우스 노이즈를 prior noise로 수신?하여 500차원 ReLu layer에 mapping\\\n",
    "4096차원 이미지 특징 벡터를 2000차원 ReLu hidden layer에 mapping\\\n",
    "이 두 layer는 생성된 단어 벡터를 출력하는 200차원 선형 레이어의 공동 표현에 mapping\n",
    "\n",
    "\n",
    "가장 잘 작동하는 모델의 D\\\n",
    "각각 단어 벡터 및 이미지 특징을 위한 500 및 1200차원 ReLu 은닉층과 1000단위 및 최종적으로 하나의 단일 시그모이드 단위에 공급되는 결합 층으로 3개 조각이 있는 최대 출력 층으로 구성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41dd68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a99863",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # 배치 사이즈, 64\n",
    "num_channels = 1 # 채널 수, 흑백 영상이므로 1?\n",
    "num_classes = 10 # 클래스 수, 10\n",
    "image_size = 28 # 이미지 차원, size, 28\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93d1f3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (70000, 28, 28, 1)\n",
      "Shape of training labels: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "# mnist dataset 로드\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# x_train + x_test = all_digits\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "\n",
    "# y_train + y_test = all_labels\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# 255로 나누어서 [0, 1] 값을 갖게 만듦.\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "\n",
    "# width = 28, height = 28, channel = 1으로 reshape함\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "\n",
    "# to_categorical 사용하여 크기가 10으로 원-핫 인코딩\n",
    "all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd817f30",
   "metadata": {},
   "source": [
    "일반(무조건) GAN에서는 정규 분포에서 노이즈(일부 고정 차원)를 샘플링하는 것으로 시작합니다. 우리의 경우 클래스 레이블도 고려해야 합니다. 판별기(생성된 이미지 입력)뿐만 아니라 생성기(노이즈 입력)의 입력 채널에 클래스 수를 추가해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab264cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 11\n"
     ]
    }
   ],
   "source": [
    "# z : latent_dim, 128\n",
    "# y : num_classes, 클래스 수(10)\n",
    "# x : num_channels, 채널 수(1)\n",
    "generator_in_channels = latent_dim + num_classes # G(z|y)\n",
    "discriminator_in_channels = num_channels + num_classes # D(x|y)\n",
    "print(generator_in_channels, discriminator_in_channels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "185e3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((28, 28, discriminator_in_channels)), # 28 * 28\n",
    "        # 컨볼루션 곱. filters=64, kernel_size=(3, 3), strides=(2, 2), padding=\"same\"\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        # ReLU 활성화 함수\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        # 컨볼루션 곱. filters=128\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        # 풀링\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        # Dense : 뉴런의 입력과 출력을 연결해주는 역할\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense(7 * 7 * generator_in_channels), # 7 * 7\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # data 언패킹\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # generated_images : G가 random_vector_labels를 이용하여 생성한 이미지\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "        \n",
    "        \n",
    "        # generated_images와 원-핫 인코딩한 labels를 concat => fake_image_and_labels\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        # real_images와 원-핫 인코딩한 labels를 concat => real_image_and_labels\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "        \n",
    "        # labels 초기화? batch_size만큼 1과 0을 가진????\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # D 훈련\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            # D의 loss_fu이 d_loss? labels와 predictions\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        # tape.gradient 사용하여 자동 미분하여 grads 구함\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        # 옵티마이저 거치고 gradients 적용?\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # batch size * latent_dim 만큼의 random_latent_vectors\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        # \n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # G 학습 (D 고정?)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # random_vector_labels 이용해서 fake_images 생성\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            # fake_image_and_labels = fake_images + image_one_hot_labels\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            # 그 fake_image_and_lables 이용해서 D의 prediction 생성\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            # g_loss는 missleading_labels????와 predictions를 이용한 것\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "            \n",
    "        # tape.gradient 사용하여 자동 미분하여 grads 구함\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        # 옵티마이저 거치고 gradients 적용?\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # g_loss 사용해서 G의 상태 업데이트?\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        # d_loss 사용해서 D의 상태 업데이트?\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc4fe43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1094/1094 [==============================] - 945s 861ms/step - g_loss: 1.5388 - d_loss: 0.4112\n",
      "Epoch 2/20\n",
      "1094/1094 [==============================] - 677s 619ms/step - g_loss: 1.5309 - d_loss: 0.4309\n",
      "Epoch 3/20\n",
      "1094/1094 [==============================] - 734s 671ms/step - g_loss: 1.9389 - d_loss: 0.3263\n",
      "Epoch 4/20\n",
      "1094/1094 [==============================] - 754s 689ms/step - g_loss: 2.6134 - d_loss: 0.1778\n",
      "Epoch 5/20\n",
      "1094/1094 [==============================] - 803s 734ms/step - g_loss: 2.9037 - d_loss: 0.1897\n",
      "Epoch 6/20\n",
      "1094/1094 [==============================] - 836s 764ms/step - g_loss: 1.2051 - d_loss: 0.5565\n",
      "Epoch 7/20\n",
      "1094/1094 [==============================] - 828s 757ms/step - g_loss: 1.0425 - d_loss: 0.6276\n",
      "Epoch 8/20\n",
      "1094/1094 [==============================] - 21980s 20s/step - g_loss: 0.9151 - d_loss: 0.6521\n",
      "Epoch 9/20\n",
      "1094/1094 [==============================] - 1240s 1s/step - g_loss: 0.8615 - d_loss: 0.6633\n",
      "Epoch 10/20\n",
      " 403/1094 [==========>...................] - ETA: 1:08:51 - g_loss: 0.8331 - d_loss: 0.6683"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20228/662719055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcond_gan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    # BinaryCrossentropy: 실제 레이블과 예측 레이블 간의 교차 엔트로피 손실을 계산(loss_fn)\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05779cce",
   "metadata": {},
   "source": [
    "여기에서는 먼저 정규 분포에서 노이즈를 샘플링한 다음 이를 num_interpolation여러 번 반복하고 그에 따라 결과를 재구성합니다. num_interpolation 그런 다음 레이블 들여쓰기가 일정 비율로 존재하도록 균일하게 배포합니다 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6243433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CGAN 형식으로 학습된 G인 trained_gen\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 1  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 5  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = tf.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation.gif\", converted_images, fps=1)\n",
    "embed.embed_file(\"animation.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af65d2e",
   "metadata": {},
   "source": [
    "FID 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7d42d",
   "metadata": {},
   "source": [
    "FID 점수는 사전 훈련된 Inception v3 모델을 먼저 로드하여 계산\\\n",
    "실제 이미지와 생성된 이미지에 대한 특징 벡터 컬렉션이 두 개 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aed265",
   "metadata": {},
   "source": [
    "$d^2 = ||mu_1 – mu_2||^2 + Tr(C_1 + C_2 – 2*sqrt(C_1*C_2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0635da5",
   "metadata": {},
   "source": [
    "d^2는 점수\\\n",
    "mu_1, mu_2는 실제 이미지와 생성된 이미지의 특징별 평균\\\n",
    "C_1, C_2 는 실제 및 생성된 특징 벡터에 대한 공분산 행렬\\\n",
    "||mu_1 – mu_2||^2 는 두 평균 벡터 간의 차 제곱합\\\n",
    "Tr은 추적 선형 대수 연산 , 예를 들어 정사각형 행렬의 주대각선을 따라 요소의 합\\\n",
    "sqrt는 두 공분산 행렬 간의 곱으로 주어진 정사각 행렬의 제곱근"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6174a",
   "metadata": {},
   "source": [
    "act1과 act2에 실제 이미지와 생성된 이미지의 특징 벡터 각각 넣어주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate frechet inception distance\n",
    "def calculate_fid(act1, act2):\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3d4bc",
   "metadata": {},
   "source": [
    "먼저, inception v3를 사용해서 이미지의 특징 벡터를 추출해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09718fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "inception_url = 'https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4'\n",
    "feature_model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(inception_url, output_shape=(2048,), trainable = False)\n",
    "])\n",
    "feature_model.build([None, 299, 299, 3])\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff2c75",
   "metadata": {},
   "source": [
    "WandB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f45e50",
   "metadata": {},
   "source": [
    "WandB(Weights & Biases)란 더 나은 모델을 빨리 만들 수 있도록 도와주는 머신러닝 Experiment tracking tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "\n",
    "wandb.init(project=\"my-test-project\", entity=\"ujin2129\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ce1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 100,\n",
    "  \"batch_size\": 128\n",
    "}\n",
    "\n",
    "# ... Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  # ...\n",
    "  wandb.tensorflow.log(tf.summary.merge_all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
